{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import mannwhitneyu, chi2_contingency, ttest_ind\n",
    "# automated feature engineering\n",
    "import featuretools as ft\n",
    "\n",
    "# Filter out pandas warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "start = \"\\033[1m\"  # Bold text\n",
    "end = \"\\033[0;0m\"  # Reset text\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows, pd.options.display.max_columns\n",
    "\n",
    "# https://thispointer.com/python-pandas-how-to-display-full-dataframe-i-e-print-all-rows-columns-without-truncation/\n",
    "# Print all the contents of a pandas dataframe\n",
    "pd.set_option(\n",
    "    \"display.max_rows\", None\n",
    ")  # Print unlimited number of rows by setting to None, default is 10\n",
    "pd.set_option(\n",
    "    \"display.max_columns\", None\n",
    ")  # Do not truncate columns to display all of them by setting to None\n",
    "pd.set_option(\n",
    "    \"display.width\", None\n",
    ")  # Auto-detect the width of dataframe to display all columns in single line by setting to None\n",
    "pd.set_option(\n",
    "    \"display.max_colwidth\", None\n",
    ")  # Auto detect the max size of column and print contents of that column without truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../training_data/X_train.csv\")\n",
    "X_test = pd.read_csv(\"../training_data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"../training_data/y_train.csv\")\n",
    "y_test = pd.read_csv(\"../training_data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def evaluate_model(model, model_params, X_train, y_train, X_test, y_test):\n",
    "    # Adjust model with provided parameters\n",
    "    model.set_params(**model_params)\n",
    "    \n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_imputed, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_imputed)\n",
    "    y_pred_proba = model.predict_proba(X_test_imputed)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Convert the classification report into a DataFrame\n",
    "    metrics_df = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    # Add accuracy and AUC to the DataFrame\n",
    "    metrics_df.loc['Accuracy', 'precision'] = accuracy\n",
    "    metrics_df.loc['AUC', 'precision'] = auc_score\n",
    "    metrics_df.loc[['Accuracy', 'AUC'], ['recall', 'f1-score']] = np.nan  # Set non-applicable columns as NaN\n",
    "    # Add the model name in the df\n",
    "    metrics_df['model'] = model.__class__.__name__\n",
    "    \n",
    "    return metrics_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time()\n",
    "# xgb_params = {'tree_method': 'gpu_hist'}\n",
    "# xgb_metrics_df = evaluate_model(XGBClassifier(random_state=50), xgb_params, X_train, y_train, X_test, y_test)\n",
    "# end = time.time()\n",
    "# print(\"[XGB] Time taken in seconds: \", end - start)\n",
    "\n",
    "# # RandomForestClassifier using 4 cores\n",
    "# start = time.time()\n",
    "# rf_params = {'n_jobs': 4}\n",
    "# rf_metrics_df = evaluate_model(RandomForestClassifier(random_state=50), rf_params, X_train, y_train, X_test, y_test)\n",
    "# end = time.time()\n",
    "# print(\"[RF] Time taken in seconds: \", end - start)\n",
    "\n",
    "# # LightGBM\n",
    "# start = time.time()\n",
    "# lgb_params = {'objective': 'binary', 'metric': 'auc', 'seed': 50, 'verbose': -1}\n",
    "# lgb_metrics_df = evaluate_model(lgb.LGBMClassifier(), lgb_params, X_train, y_train, X_test, y_test)\n",
    "# end = time.time()\n",
    "# print(\"[LGBM] Time taken in seconds: \", end - start)\n",
    "\n",
    "# # CART (Decision Tree)\n",
    "# start = time.time()\n",
    "# cart_metrics_df = evaluate_model(DecisionTreeClassifier(random_state=50), {}, X_train, y_train, X_test, y_test)\n",
    "# end = time.time()\n",
    "# print(\"[CART] Time taken in seconds: \", end - start)\n",
    "\n",
    "# # Extra Trees\n",
    "# start = time.time()\n",
    "# et_metrics_df = evaluate_model(ExtraTreesClassifier(random_state=50), {}, X_train, y_train, X_test, y_test)\n",
    "# end = time.time()\n",
    "# print(\"[ExtraTrees] Time taken in seconds: \", end - start)\n",
    "\n",
    "# # CatBoost\n",
    "# start = time.time()\n",
    "# catboost_params = {\n",
    "#     'task_type': 'GPU',\n",
    "#     'devices': '0',  # Specifies the GPU ID to use. For multiple GPUs, use '0:1:2' for GPUs 0, 1, and 2, for example.\n",
    "#     'random_seed': 50, \n",
    "#     'silent': True\n",
    "# }\n",
    "\n",
    "# # Evaluate CatBoost model\n",
    "# catboost_metrics_df = evaluate_model(CatBoostClassifier(), catboost_params, X_train, y_train, X_test, y_test)\n",
    "# end = time.time()\n",
    "# print(\"[CB] Time taken in seconds: \", end - start)\n",
    "\n",
    "# #adaboost\n",
    "# start = time.time()\n",
    "# ada_metrics_df = evaluate_model(AdaBoostClassifier(random_state=50),{}, X_train, y_train, X_test, y_test)\n",
    "# end = time.time()\n",
    "# print(\"[ADA] Time taken in seconds: \", end - start)\n",
    "\n",
    "# #ID3\n",
    "# start = time.time()\n",
    "# dt_params = {'criterion': 'entropy', 'random_state': 50}\n",
    "# id3_metrics_df = evaluate_model(DecisionTreeClassifier(), dt_params, X_train, y_train, X_test, y_test)\n",
    "# end = time.time()\n",
    "# print(\"[ID3] Time taken in seconds: \", end - start)\n",
    "# print(id3_metrics_df)\n",
    "\n",
    "# xgb_metrics_df\n",
    "# rf_metrics_df\n",
    "# lgb_metrics_df\n",
    "# catboost_metrics_df\n",
    "# et_metrics_df\n",
    "# cart_metrics_df\n",
    "# ada_metrics_df\n",
    "# id3_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration completed in 65.06 seconds.\n",
      "Best score so far: 0.7830\n",
      "Best parameters so far:\n",
      "colsample_bylevel: 0.8230311876559941\n",
      "colsample_bynode: 0.9183177229531976\n",
      "colsample_bytree: 0.9798603996543502\n",
      "gamma: 1.5789979674352437\n",
      "learning_rate: 0.12660162270835032\n",
      "max_depth: 4\n",
      "min_child_weight: 2\n",
      "n_estimators: 287\n",
      "reg_alpha: 0.0003329021156509417\n",
      "reg_lambda: 0.017336360995622795\n",
      "subsample: 0.9324945912714676\n",
      "\n",
      "Iteration completed in 58.80 seconds.\n",
      "Best score so far: 0.7830\n",
      "Best parameters so far:\n",
      "colsample_bylevel: 0.8230311876559941\n",
      "colsample_bynode: 0.9183177229531976\n",
      "colsample_bytree: 0.9798603996543502\n",
      "gamma: 1.5789979674352437\n",
      "learning_rate: 0.12660162270835032\n",
      "max_depth: 4\n",
      "min_child_weight: 2\n",
      "n_estimators: 287\n",
      "reg_alpha: 0.0003329021156509417\n",
      "reg_lambda: 0.017336360995622795\n",
      "subsample: 0.9324945912714676\n",
      "\n",
      "Iteration completed in 65.12 seconds.\n",
      "Best score so far: 0.7831\n",
      "Best parameters so far:\n",
      "colsample_bylevel: 0.8334497536903456\n",
      "colsample_bynode: 0.9756167565008131\n",
      "colsample_bytree: 0.7314577475658111\n",
      "gamma: 2.166664009351126\n",
      "learning_rate: 0.06488290737850855\n",
      "max_depth: 4\n",
      "min_child_weight: 1\n",
      "n_estimators: 288\n",
      "reg_alpha: 0.006119305214365199\n",
      "reg_lambda: 0.7345728767132583\n",
      "subsample: 0.9555201296659456\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.callbacks import DeltaYStopper\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class IterationTrackingCallback:\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "        # Lists to store scores and parameter sets\n",
    "        self.best_scores = []\n",
    "        self.best_parameters = []\n",
    "    \n",
    "    def __call__(self, res):\n",
    "        iteration_time = time.time() - self.start_time\n",
    "        print(f\"\\nIteration completed in {iteration_time:.2f} seconds.\")\n",
    "        \n",
    "        # Store the negated best score so far to correct its sign\n",
    "        best_score_so_far = -res.fun\n",
    "        self.best_scores.append(best_score_so_far)\n",
    "        print(f\"Best score so far: {best_score_so_far:.4f}\")\n",
    "\n",
    "        # Extract and store the best parameters so far\n",
    "        best_params_so_far = dict(zip(res.space.dimension_names, res.x))\n",
    "        self.best_parameters.append(best_params_so_far)\n",
    "        print(\"Best parameters so far:\")\n",
    "        for param_name, param_value in best_params_so_far.items():\n",
    "            print(f\"{param_name}: {param_value}\")\n",
    "\n",
    "        self.start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the callback\n",
    "iteration_callback = IterationTrackingCallback()\n",
    "\n",
    "# Define your XGBClassifier and BayesSearchCV as before\n",
    "model = XGBClassifier(tree_method='gpu_hist', random_state=42)\n",
    "\n",
    "search_spaces = {\n",
    "    'n_estimators': Integer(250, 300),\n",
    "    'max_depth': Integer(3, 6),\n",
    "    'learning_rate': Real(0.05, 0.2, 'log-uniform'),\n",
    "    'subsample': Real(0.85, 1.0),\n",
    "    'colsample_bytree': Real(0.7, 1.0),\n",
    "    'colsample_bylevel': Real(0.7, 1.0),  # Added based on your current range\n",
    "    'colsample_bynode': Real(0.7, 1.0),  # Added for experimentation\n",
    "    'min_child_weight': Integer(1, 3),\n",
    "    'gamma': Real(0, 5),\n",
    "    'reg_alpha': Real(1e-5, 1.0, 'log-uniform'),\n",
    "    'reg_lambda': Real(1e-5, 1.0, 'log-uniform'),\n",
    "}\n",
    "\n",
    "\n",
    "# Define your XGBClassifier and BayesSearchCV as before\n",
    "model = XGBClassifier(tree_method='gpu_hist', random_state=42)\n",
    "opt = BayesSearchCV(\n",
    "    estimator=model,\n",
    "    search_spaces=search_spaces,\n",
    "    n_iter=30,  # Reduced iterations for speed\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=1,  # Keep as 1 for GPU usage\n",
    "    return_train_score=True,\n",
    "    refit=True,\n",
    "    random_state=42\n",
    ")\n",
    "# Fit BayesSearchCV with the callback\n",
    "opt.fit(X_train, y_train, callback=[iteration_callback])\n",
    "\n",
    "\n",
    "# Plotting the improvement of scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iteration_callback.best_scores, marker='o')\n",
    "plt.title('Improvement of Best AUC Score over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Best AUC Score')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
