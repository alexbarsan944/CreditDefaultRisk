{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bruteforce feature engineering with featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# automated feature engineering\n",
    "import featuretools as ft\n",
    "\n",
    "# Filter out pandas warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows, pd.options.display.max_columns\n",
    "\n",
    "# https://thispointer.com/python-pandas-how-to-display-full-dataframe-i-e-print-all-rows-columns-without-truncation/\n",
    "# Print all the contents of a pandas dataframe\n",
    "pd.set_option(\n",
    "    \"display.max_rows\", None\n",
    ")  # Print unlimited number of rows by setting to None, default is 10\n",
    "pd.set_option(\n",
    "    \"display.max_columns\", None\n",
    ")  # Do not truncate columns to display all of them by setting to None\n",
    "pd.set_option(\n",
    "    \"display.width\", None\n",
    ")  # Auto-detect the width of dataframe to display all columns in single line by setting to None\n",
    "pd.set_option(\n",
    "    \"display.max_colwidth\", None\n",
    ")  # Auto detect the max size of column and print contents of that column without truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "train\n",
      "Memory usage of dataframe is 286.23 MB\n",
      "Memory usage after optimization is: 59.54 MB\n",
      "Decreased by 79.2%\n",
      "--------------------------------------------------------------------------------\n",
      "test\n",
      "Memory usage of dataframe is 45.00 MB\n",
      "Memory usage after optimization is: 9.40 MB\n",
      "Decreased by 79.1%\n",
      "--------------------------------------------------------------------------------\n",
      "bureau_balance\n",
      "Memory usage of dataframe is 624.85 MB\n",
      "Memory usage after optimization is: 156.21 MB\n",
      "Decreased by 75.0%\n",
      "--------------------------------------------------------------------------------\n",
      "bureau\n",
      "Memory usage of dataframe is 222.62 MB\n",
      "Memory usage after optimization is: 78.57 MB\n",
      "Decreased by 64.7%\n",
      "--------------------------------------------------------------------------------\n",
      "credit_card_balance\n",
      "Memory usage of dataframe is 673.88 MB\n",
      "Memory usage after optimization is: 263.69 MB\n",
      "Decreased by 60.9%\n",
      "--------------------------------------------------------------------------------\n",
      "installments_payments\n",
      "Memory usage of dataframe is 830.41 MB\n",
      "Memory usage after optimization is: 311.40 MB\n",
      "Decreased by 62.5%\n",
      "--------------------------------------------------------------------------------\n",
      "pos_cash_balance\n",
      "Memory usage of dataframe is 610.43 MB\n",
      "Memory usage after optimization is: 171.69 MB\n",
      "Decreased by 71.9%\n",
      "--------------------------------------------------------------------------------\n",
      "previous_application\n",
      "Memory usage of dataframe is 471.48 MB\n",
      "Memory usage after optimization is: 130.62 MB\n",
      "Decreased by 72.3%\n"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\"iterate through all the columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"train\")\n",
    "app_train = import_data(\"../data/application_train.csv\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"test\")\n",
    "app_test = import_data(\"../data/application_test.csv\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"bureau_balance\")\n",
    "bureau_balance = import_data(\"../data/bureau_balance.csv\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"bureau\")\n",
    "bureau = import_data(\"../data/bureau.csv\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"credit_card_balance\")\n",
    "credit = import_data(\"../data/credit_card_balance.csv\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"installments_payments\")\n",
    "installments = import_data(\"../data/installments_payments.csv\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"pos_cash_balance\")\n",
    "cash = import_data(\"../data/POS_CASH_balance.csv\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"previous_application\")\n",
    "previous = import_data(\"../data/previous_application.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: clients\n",
       "  DataFrames:\n",
       "    app [Rows: 307511, Columns: 134]\n",
       "    bureau [Rows: 1716428, Columns: 17]\n",
       "    previous [Rows: 1670214, Columns: 37]\n",
       "    bureau_balance [Rows: 27299925, Columns: 4]\n",
       "    cash [Rows: 10001358, Columns: 9]\n",
       "    installments [Rows: 13605401, Columns: 10]\n",
       "    credit [Rows: 3840312, Columns: 24]\n",
       "  Relationships:\n",
       "    bureau.SK_ID_CURR -> app.SK_ID_CURR\n",
       "    bureau_balance.SK_ID_BUREAU -> bureau.SK_ID_BUREAU\n",
       "    previous.SK_ID_CURR -> app.SK_ID_CURR\n",
       "    cash.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    installments.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    credit.SK_ID_PREV -> previous.SK_ID_PREV"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = app_train\n",
    "\n",
    "grouped = bureau.groupby(\"SK_ID_CURR\")\n",
    "app[\"debt_credit_ratio_None\"] = (\n",
    "    grouped[\"AMT_CREDIT_SUM_DEBT\"].sum() / grouped[\"AMT_CREDIT_SUM\"].sum()\n",
    ")\n",
    "app[\"credit_annuity_ratio\"] = app[\"AMT_CREDIT\"] / app[\"AMT_ANNUITY\"]\n",
    "prev_sorted = previous.sort_values(by=[\"SK_ID_CURR\", \"DAYS_DECISION\"])\n",
    "app[\"prev_PRODUCT_COMBINATION\"] = prev_sorted.groupby(\"SK_ID_CURR\")[\n",
    "    \"PRODUCT_COMBINATION\"\n",
    "].last()\n",
    "app[\"DAYS_CREDIT_mean\"] = bureau.groupby(\"SK_ID_CURR\")[\"DAYS_CREDIT\"].mean()\n",
    "app[\"credit_goods_price_ratio\"] = app[\"AMT_CREDIT\"] / app[\"AMT_GOODS_PRICE\"]\n",
    "active_loans = bureau[bureau[\"CREDIT_ACTIVE\"] == \"Active\"]\n",
    "app[\"last_active_DAYS_CREDIT\"] = active_loans.groupby(\"SK_ID_CURR\")[\"DAYS_CREDIT\"].max()\n",
    "app[\"credit_downpayment\"] = app[\"AMT_GOODS_PRICE\"] - app[\"AMT_CREDIT\"]\n",
    "app[\"AGE_INT\"] = (app[\"DAYS_BIRTH\"] / -365).astype(int)\n",
    "\n",
    "installments[\"diff\"] = installments[\"AMT_PAYMENT\"] - installments[\"AMT_INSTALMENT\"]\n",
    "filtered = installments[installments[\"DAYS_INSTALMENT\"] > -1000]\n",
    "grouped = (\n",
    "    filtered.groupby([\"SK_ID_PREV\", \"SK_ID_CURR\"])[\"diff\"]\n",
    "    .mean()\n",
    "    .groupby(\"SK_ID_CURR\")\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "app[\"installment_payment_ratio_1000_mean_mean\"] = grouped\n",
    "max_installment = installments.groupby(\"SK_ID_CURR\")[\"AMT_INSTALMENT\"].max()\n",
    "app[\"annuity_to_max_installment_ratio\"] = app[\"AMT_ANNUITY\"] / max_installment\n",
    "app[\"EXT_SOURCES_MEAN\"] = app[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].mean(\n",
    "    axis=1\n",
    ")\n",
    "app[\"EXT_SOURCES_MAX\"] = app[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].max(\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "installments[\"diff\"] = installments[\"AMT_PAYMENT\"] - installments[\"AMT_INSTALMENT\"]\n",
    "filtered = installments[installments[\"DAYS_INSTALMENT\"] > -1000]\n",
    "grouped = (\n",
    "    filtered.groupby([\"SK_ID_PREV\", \"SK_ID_CURR\"])[\"diff\"]\n",
    "    .mean()\n",
    "    .groupby(\"SK_ID_CURR\")\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "app[\"installment_payment_ratio_1000_mean_mean\"] = grouped\n",
    "max_installment = installments.groupby(\"SK_ID_CURR\")[\"AMT_INSTALMENT\"].max()\n",
    "app[\"annuity_to_max_installment_ratio\"] = app[\"AMT_ANNUITY\"] / max_installment\n",
    "\n",
    "\n",
    "es = ft.EntitySet(id=\"clients\")\n",
    "# For dataframes with an existing unique index\n",
    "es = es.add_dataframe(dataframe_name=\"app\", dataframe=app, index=\"SK_ID_CURR\")\n",
    "es = es.add_dataframe(dataframe_name=\"bureau\", dataframe=bureau, index=\"SK_ID_BUREAU\")\n",
    "es = es.add_dataframe(dataframe_name=\"previous\", dataframe=previous, index=\"SK_ID_PREV\")\n",
    "\n",
    "# For dataframes that do not have a unique index, manually add an index column\n",
    "bureau_balance[\"bureaubalance_index\"] = range(1, len(bureau_balance) + 1)\n",
    "cash[\"cash_index\"] = range(1, len(cash) + 1)\n",
    "installments[\"installments_index\"] = range(1, len(installments) + 1)\n",
    "credit[\"credit_index\"] = range(1, len(credit) + 1)\n",
    "\n",
    "# Now add these dataframes to the EntitySet\n",
    "es = es.add_dataframe(\n",
    "    dataframe_name=\"bureau_balance\",\n",
    "    dataframe=bureau_balance,\n",
    "    index=\"bureaubalance_index\",\n",
    ")\n",
    "es = es.add_dataframe(dataframe_name=\"cash\", dataframe=cash, index=\"cash_index\")\n",
    "es = es.add_dataframe(\n",
    "    dataframe_name=\"installments\", dataframe=installments, index=\"installments_index\"\n",
    ")\n",
    "es = es.add_dataframe(dataframe_name=\"credit\", dataframe=credit, index=\"credit_index\")\n",
    "\n",
    "# Define relationships based on logical connections (foreign keys) between the dataframes\n",
    "relationships = [\n",
    "    (\"app\", \"SK_ID_CURR\", \"bureau\", \"SK_ID_CURR\"),\n",
    "    (\"bureau\", \"SK_ID_BUREAU\", \"bureau_balance\", \"SK_ID_BUREAU\"),\n",
    "    (\"app\", \"SK_ID_CURR\", \"previous\", \"SK_ID_CURR\"),\n",
    "    (\"previous\", \"SK_ID_PREV\", \"cash\", \"SK_ID_PREV\"),\n",
    "    (\"previous\", \"SK_ID_PREV\", \"installments\", \"SK_ID_PREV\"),\n",
    "    (\"previous\", \"SK_ID_PREV\", \"credit\", \"SK_ID_PREV\"),\n",
    "]\n",
    "\n",
    "# Add relationships to the EntitySet\n",
    "for parent_df, parent_col, child_df, child_col in relationships:\n",
    "    es.add_relationship(\n",
    "        parent_dataframe_name=parent_df,\n",
    "        parent_column_name=parent_col,\n",
    "        child_dataframe_name=child_df,\n",
    "        child_column_name=child_col,\n",
    "    )\n",
    "\n",
    "\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent: app, Parent Variable: SK_ID_CURR\n",
      "\n",
      "         FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20\n",
      "100002                 0                 0                 0                 0\n",
      "100003                 0                 0                 0                 0\n",
      "100004                 0                 0                 0                 0\n",
      "100006                 0                 0                 0                 0\n",
      "100007                 0                 0                 0                 0\n",
      "\n",
      "Child: bureau, Child Variable: SK_ID_CURR\n",
      "\n",
      "          SK_ID_CURR  SK_ID_BUREAU CREDIT_ACTIVE CREDIT_CURRENCY\n",
      "5714472      162297       5714472        Active      currency 1\n",
      "5714473      162297       5714473        Closed      currency 1\n",
      "5714474      162297       5714474        Active      currency 1\n",
      "5714475      402440       5714475        Active      currency 1\n",
      "5714482      238881       5714482        Closed      currency 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Parent: app, Parent Variable: SK_ID_CURR\\n\\n\", app.iloc[:, 111:115].head())\n",
    "print(\"\\nChild: bureau, Child Variable: SK_ID_CURR\\n\\n\", bureau.iloc[10:30, :4].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Primitives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>dask_compatible</th>\n",
       "      <th>spark_compatible</th>\n",
       "      <th>description</th>\n",
       "      <th>valid_inputs</th>\n",
       "      <th>return_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_unique_days_of_month</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the number of unique days of month.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Datetime)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first_last_time_delta</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the time between the first and last time value in seconds.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Datetime) (Semantic Tags = ['time_index'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Double) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max_consecutive_false</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the maximum number of consecutive False values in the input</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Boolean)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num_consecutive_less_mean</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the length of the longest subsequence below the mean.</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['numeric'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = IntegerNullable) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time_since_first</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Calculates the time elapsed since the first datetime (in seconds).</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Datetime) (Semantic Tags = ['time_index'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Double) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>count_below_mean</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the number of values that are below the mean.</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['numeric'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = IntegerNullable) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_greater_than</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the number of values greater than a controllable threshold.</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['numeric'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>percent_true</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the percent of `True` values.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Boolean)&gt;, &lt;ColumnSchema (Logical Type = BooleanNullable)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Double) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_false_since_last_true</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Calculates the number of 'False' values since the last `True` value. Description: From a series of Booleans, find the last record with a `True` value. Return the count of 'False' values between that record and the end of the series. Return nan if no values are `True`. Any nan values in the input are ignored. A 'True' value in the last row will result in a count of 0. Inputs are converted too booleans before calculating the result. Examples: &gt;&gt;&gt; num_false_since_last_true = NumFalseSinceLastTrue() &gt;&gt;&gt; num_false_since_last_true([True, False, True, False, False]) 2</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Boolean)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = IntegerNullable) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>date_first_event</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the first datetime from a list of datetimes.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Datetime) (Semantic Tags = ['time_index'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Datetime)&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name         type  dask_compatible  spark_compatible  \\\n",
       "0     n_unique_days_of_month  aggregation            False             False   \n",
       "1      first_last_time_delta  aggregation            False             False   \n",
       "2      max_consecutive_false  aggregation            False             False   \n",
       "3  num_consecutive_less_mean  aggregation            False             False   \n",
       "4           time_since_first  aggregation            False             False   \n",
       "5           count_below_mean  aggregation            False             False   \n",
       "6         count_greater_than  aggregation            False             False   \n",
       "7               percent_true  aggregation             True             False   \n",
       "8  num_false_since_last_true  aggregation            False             False   \n",
       "9           date_first_event  aggregation            False             False   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               description  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Determines the number of unique days of month.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Determines the time between the first and last time value in seconds.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Determines the maximum number of consecutive False values in the input   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Determines the length of the longest subsequence below the mean.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Calculates the time elapsed since the first datetime (in seconds).   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Determines the number of values that are below the mean.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Determines the number of values greater than a controllable threshold.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Determines the percent of `True` values.   \n",
       "8  Calculates the number of 'False' values since the last `True` value. Description: From a series of Booleans, find the last record with a `True` value. Return the count of 'False' values between that record and the end of the series. Return nan if no values are `True`. Any nan values in the input are ignored. A 'True' value in the last row will result in a count of 0. Inputs are converted too booleans before calculating the result. Examples: >>> num_false_since_last_true = NumFalseSinceLastTrue() >>> num_false_since_last_true([True, False, True, False, False]) 2   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Determines the first datetime from a list of datetimes.   \n",
       "\n",
       "                                                                               valid_inputs  \\\n",
       "0                                                  <ColumnSchema (Logical Type = Datetime)>   \n",
       "1                 <ColumnSchema (Logical Type = Datetime) (Semantic Tags = ['time_index'])>   \n",
       "2                                                   <ColumnSchema (Logical Type = Boolean)>   \n",
       "3                                              <ColumnSchema (Semantic Tags = ['numeric'])>   \n",
       "4                 <ColumnSchema (Logical Type = Datetime) (Semantic Tags = ['time_index'])>   \n",
       "5                                              <ColumnSchema (Semantic Tags = ['numeric'])>   \n",
       "6                                              <ColumnSchema (Semantic Tags = ['numeric'])>   \n",
       "7  <ColumnSchema (Logical Type = Boolean)>, <ColumnSchema (Logical Type = BooleanNullable)>   \n",
       "8                                                   <ColumnSchema (Logical Type = Boolean)>   \n",
       "9                 <ColumnSchema (Logical Type = Datetime) (Semantic Tags = ['time_index'])>   \n",
       "\n",
       "                                                                     return_type  \n",
       "0          <ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])>  \n",
       "1           <ColumnSchema (Logical Type = Double) (Semantic Tags = ['numeric'])>  \n",
       "2          <ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])>  \n",
       "3  <ColumnSchema (Logical Type = IntegerNullable) (Semantic Tags = ['numeric'])>  \n",
       "4           <ColumnSchema (Logical Type = Double) (Semantic Tags = ['numeric'])>  \n",
       "5  <ColumnSchema (Logical Type = IntegerNullable) (Semantic Tags = ['numeric'])>  \n",
       "6          <ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])>  \n",
       "7           <ColumnSchema (Logical Type = Double) (Semantic Tags = ['numeric'])>  \n",
       "8  <ColumnSchema (Logical Type = IntegerNullable) (Semantic Tags = ['numeric'])>  \n",
       "9                                       <ColumnSchema (Logical Type = Datetime)>  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primitives = ft.list_primitives()\n",
    "primitives[primitives[\"type\"] == \"aggregation\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.enable()\n",
    "del bureau_balance, bureau, credit, installments, cash, previous\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_application_columns(df):\n",
    "    \"\"\"Drop features based on permutation feature importance.\"\"\"\n",
    "    drop_list = [\n",
    "        \"CNT_CHILDREN\",\n",
    "        \"CNT_FAM_MEMBERS\",\n",
    "        \"HOUR_APPR_PROCESS_START\",\n",
    "        \"FLAG_EMP_PHONE\",\n",
    "        \"FLAG_MOBIL\",\n",
    "        \"FLAG_CONT_MOBILE\",\n",
    "        \"FLAG_EMAIL\",\n",
    "        \"FLAG_PHONE\",\n",
    "        \"FLAG_OWN_REALTY\",\n",
    "        \"REG_REGION_NOT_LIVE_REGION\",\n",
    "        \"REG_REGION_NOT_WORK_REGION\",\n",
    "        \"REG_CITY_NOT_WORK_CITY\",\n",
    "        \"OBS_30_CNT_SOCIAL_CIRCLE\",\n",
    "        \"OBS_60_CNT_SOCIAL_CIRCLE\",\n",
    "        \"AMT_REQ_CREDIT_BUREAU_DAY\",\n",
    "        \"AMT_REQ_CREDIT_BUREAU_MON\",\n",
    "        \"AMT_REQ_CREDIT_BUREAU_YEAR\",\n",
    "        \"COMMONAREA_MODE\",\n",
    "        \"NONLIVINGAREA_MODE\",\n",
    "        \"ELEVATORS_MODE\",\n",
    "        \"NONLIVINGAREA_AVG\",\n",
    "        \"FLOORSMIN_MEDI\",\n",
    "        \"LANDAREA_MODE\",\n",
    "        \"NONLIVINGAREA_MEDI\",\n",
    "        \"LIVINGAPARTMENTS_MODE\",\n",
    "        \"FLOORSMIN_AVG\",\n",
    "        \"LANDAREA_AVG\",\n",
    "        \"FLOORSMIN_MODE\",\n",
    "        \"LANDAREA_MEDI\",\n",
    "        \"COMMONAREA_MEDI\",\n",
    "        \"YEARS_BUILD_AVG\",\n",
    "        \"COMMONAREA_AVG\",\n",
    "        \"BASEMENTAREA_AVG\",\n",
    "        \"BASEMENTAREA_MODE\",\n",
    "        \"NONLIVINGAPARTMENTS_MEDI\",\n",
    "        \"BASEMENTAREA_MEDI\",\n",
    "        \"LIVINGAPARTMENTS_AVG\",\n",
    "        \"ELEVATORS_AVG\",\n",
    "        \"YEARS_BUILD_MEDI\",\n",
    "        \"ENTRANCES_MODE\",\n",
    "        \"NONLIVINGAPARTMENTS_MODE\",\n",
    "        \"LIVINGAREA_MODE\",\n",
    "        \"LIVINGAPARTMENTS_MEDI\",\n",
    "        \"YEARS_BUILD_MODE\",\n",
    "        \"YEARS_BEGINEXPLUATATION_AVG\",\n",
    "        \"ELEVATORS_MEDI\",\n",
    "        \"LIVINGAREA_MEDI\",\n",
    "        \"YEARS_BEGINEXPLUATATION_MODE\",\n",
    "        \"NONLIVINGAPARTMENTS_AVG\",\n",
    "        \"HOUSETYPE_MODE\",\n",
    "        \"FONDKAPREMONT_MODE\",\n",
    "        \"EMERGENCYSTATE_MODE\",\n",
    "    ]\n",
    "    # Drop most flag document columns\n",
    "    for doc_num in [2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21]:\n",
    "        drop_list.append(\"FLAG_DOCUMENT_{}\".format(doc_num))\n",
    "    df.drop(drop_list, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "app = drop_application_columns(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_agg_primitives = [\"sum\", \"mean\", \"count\", \"max\", \"min\", \"std\"]\n",
    "\n",
    "\n",
    "# Now you can run dfs with the entity set you've created\n",
    "feature_names = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name=\"app\",\n",
    "    agg_primitives=default_agg_primitives,\n",
    "    max_depth=2,\n",
    "    features_only=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "with open(\"..data/features_data/feature_names_final.txt\", \"w\") as f:\n",
    "    for item in feature_names:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
